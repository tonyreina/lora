# Simplified single configuration file
# All essential settings in one place

# Mode: train or inference
mode: train

# Global settings
seed: 816
output_dir: ./checkpoints/model

# Model configuration
model:
  name: microsoft/Phi-4-mini-instruct
  max_length: 512

# LoRA settings
lora:
  r: 16
  alpha: 32
  dropout: 0.1
  target_modules: [q_proj, v_proj, k_proj, o_proj]

# Data settings
data:
  train_file: ./data/my_custom_data.jsonl
  test_split: 0.1
  validation_split: 0.1
  system_prompt: >
    You are a careful medical assistant providing evidence-based information. 
    Always end with 'This response was generated by AI. Please check with medical practitioners.'

# Training settings
training:
  batch_size: 4
  learning_rate: 2e-4
  num_epochs: 3
  gradient_accumulation_steps: 8
  logging_steps: 10
  early_stopping_patience: 3

# Inference settings  
inference:
  adapter_path: ${output_dir}/lora_adapter
  interactive: true
  demo_question: "What are the latest treatment guidelines for hypertension?"
  max_new_tokens: 512
  temperature: 0.6
  top_p: 0.9

# Quick presets (uncomment to use)
# For fast testing:
# training.num_epochs: 1
# training.batch_size: 1

# For production:  
# training.num_epochs: 10
# training.learning_rate: 1e-4