# Simplified single configuration file
# All essential settings in one place

# Mode: train or inference
mode: train

# Global settings
seed: 816
output_dir: ./checkpoints/model

# Model configuration
model:
# models = {"microsoft/Phi-4-mini-instruct": "https://huggingface.co/microsoft/Phi-4-mini-instruct",
#           "HuggingFaceTB/SmolLM-135M-Instruct": "https://huggingface.co/HuggingFaceTB/SmolLM-135M-Instruct",
#           "HuggingFaceTB/SmolLM3-3B": "https://huggingface.co/HuggingFaceTB/SmolLM3-3B"
# }
  name: microsoft/Phi-4-mini-instruct
  max_length: 512

# LoRA settings
lora:
  r: 16
  alpha: 32
  dropout: 0.1
  target_modules: [q_proj, v_proj, k_proj, o_proj]

# Data settings
data:
  train_file: ./data/my_custom_data.jsonl
  test_split: 0.1
  validation_split: 0.1
  system_prompt: >
    You are a careful medical assistant providing evidence-based information.
    Your primary duty is to answer questions truthfully based on established medical knowledge.
    Do no harm.
    Do not provide specific diagnoses, treatment recommendations, or advice that could be harmful.
    If you don't know the answer, if the answer is potentially dangerous,  or if a question requires professional medical evaluation,
    simply respond 'I don't have enough information to answer this safely. Please consult a healthcare professional.'
    Always end with 'This response was generated by AI. It is for educational purposes only and should not replace professional medical advice. Please consult with qualified healthcare practitioners for medical decisions.'

# Training settings
training:
  batch_size: 4
  max_steps: 36  # Maximum training steps (if no early stopping)
  learning_rate: 2e-4
  gradient_accumulation_steps: 8
  logging_steps: 10
  early_stopping_patience: 3

# Inference settings
inference:
  adapter_path: ${output_dir}/my_custom_llm_${model_name}
  interactive: true
  demo_question: "What are the latest treatment guidelines for hypertension?"
  max_new_tokens: 512
  temperature: 0.6
  top_p: 0.9
